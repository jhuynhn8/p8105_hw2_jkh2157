p8105_hw2_jkh2157
================
2025-09-30

## Loading Libraries

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(knitr)
library(readxl)
```

## Problem 1

Step 1a: Clean the data in pols-month

``` r
pols_df=
  read_csv("datasets/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate (mon, into = c("year","month","day"),sep="-") %>% 
  mutate(
    month = recode(month,`01`="Jan",`02`="Feb",`03`="Mar",`04`="Apr",`05`="May",`06`="Jun",`07`="Jul",`08`="Aug",`09`="Sep",`10`="Oct",`11`="Nov",`12`="Dec"),
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem ==1 ~ "dem"
    ),
    year=as.character(year)
  ) %>% 
  select(year,month,president,everything(),-day,-prez_gop,-prez_dem)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
knitr::kable(head(pols_df,10))
```

| year | month | president | gov_gop | sen_gop | rep_gop | gov_dem | sen_dem | rep_dem |
|:-----|:------|:----------|--------:|--------:|--------:|--------:|--------:|--------:|
| 1947 | Jan   | dem       |      23 |      51 |     253 |      23 |      45 |     198 |
| 1947 | Feb   | dem       |      23 |      51 |     253 |      23 |      45 |     198 |
| 1947 | Mar   | dem       |      23 |      51 |     253 |      23 |      45 |     198 |
| 1947 | Apr   | dem       |      23 |      51 |     253 |      23 |      45 |     198 |
| 1947 | May   | dem       |      23 |      51 |     253 |      23 |      45 |     198 |
| 1947 | Jun   | dem       |      23 |      51 |     253 |      23 |      45 |     198 |
| 1947 | Jul   | dem       |      23 |      51 |     253 |      23 |      45 |     198 |
| 1947 | Aug   | dem       |      23 |      51 |     253 |      23 |      45 |     198 |
| 1947 | Sep   | dem       |      23 |      51 |     253 |      23 |      45 |     198 |
| 1947 | Oct   | dem       |      23 |      51 |     253 |      23 |      45 |     198 |

Step 1b: Clean the data for snp.csv

``` r
snp_df=
  read_csv("datasets/fivethirtyeight_datasets/snp.csv") %>% 
  separate(date, into=c("month","date","year"), sep = "/") %>% 
  mutate(
    month = recode(month,`1`="Jan",`2`="Feb",`3`="Mar",`4`="Apr",`5`="May",`6`="Jun",`7`="Jul",`8`="Aug",`9`="Sep",`10`="Oct",`11`="Nov",`12`="Dec"),
    year=case_when(
      as.numeric(year)>=50 ~ paste0("19",year),
      as.numeric(year)<50 ~ paste0("20",year)
    )) %>% 
  mutate(year=as.character(year)) %>% 
  select(year,month,close) %>% 
  arrange(year,month)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
knitr::kable(head(snp_df,10))
```

| year | month | close |
|:-----|:------|------:|
| 1950 | Apr   | 17.96 |
| 1950 | Aug   | 18.42 |
| 1950 | Dec   | 20.43 |
| 1950 | Feb   | 17.22 |
| 1950 | Jan   | 17.05 |
| 1950 | Jul   | 17.84 |
| 1950 | Jun   | 17.69 |
| 1950 | Mar   | 17.29 |
| 1950 | May   | 18.78 |
| 1950 | Nov   | 19.51 |

Step 1c: tidy unemploymeny data

``` r
unemployment_df=
  read_csv("datasets/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols=jan:dec,
    names_to="month",
    values_to="unemployment") %>% 
  mutate(
    month=str_to_title(month),
    year=as.character(year)) %>% 
  select(year,month,unemployment)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
knitr::kable(head(unemployment_df,10))
```

| year | month | unemployment |
|:-----|:------|-------------:|
| 1948 | Jan   |          3.4 |
| 1948 | Feb   |          3.8 |
| 1948 | Mar   |          4.0 |
| 1948 | Apr   |          3.9 |
| 1948 | May   |          3.5 |
| 1948 | Jun   |          3.6 |
| 1948 | Jul   |          3.6 |
| 1948 | Aug   |          3.9 |
| 1948 | Sep   |          3.8 |
| 1948 | Oct   |          3.7 |

Step 1d: merge data sets

``` r
final_df=left_join(pols_df,snp_df,by=c("year","month"))
final_df=left_join(final_df,unemployment_df,by=c("year","month"))
knitr::kable(head(final_df,15))
```

| year | month | president | gov_gop | sen_gop | rep_gop | gov_dem | sen_dem | rep_dem | close | unemployment |
|:---|:---|:---|---:|---:|---:|---:|---:|---:|---:|---:|
| 1947 | Jan | dem | 23 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1947 | Feb | dem | 23 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1947 | Mar | dem | 23 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1947 | Apr | dem | 23 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1947 | May | dem | 23 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1947 | Jun | dem | 23 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1947 | Jul | dem | 23 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1947 | Aug | dem | 23 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1947 | Sep | dem | 23 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1947 | Oct | dem | 23 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1947 | Nov | dem | 24 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1947 | Dec | dem | 24 | 51 | 253 | 23 | 45 | 198 | NA | NA |
| 1948 | Jan | dem | 22 | 53 | 253 | 24 | 48 | 198 | NA | 3.4 |
| 1948 | Feb | dem | 22 | 53 | 253 | 24 | 48 | 198 | NA | 3.8 |
| 1948 | Mar | dem | 22 | 53 | 253 | 24 | 48 | 198 | NA | 4.0 |

The pols data set (822 rows and 9 columns) contains the monthly counts
of Democratic and Republican governors,senators, and representatives.
The snp data set (787 rows and 3 columns) looks at the monthly closing
values of the S&P index, starting in 1950 which explains why there are
some NA values. The unemployment data set (816 rows and 3 columns)
reports monthly US unemployment rates starting in 1948. After cleaning
and merging these data sets we get a new frame that ranges from Jan 1947
to Jun 2015, with variables including year, month, president,
congressional bodies, stock market performance (close), and unemployment
rates. The dimensions of the final table contains 822 rows and 11
columns.

## Problem 2

Step 2a: Cleaning up mrTrash

``` r
mr_trash_df=
  read_excel("datasets/trash_wheel_data2.xlsx", sheet="Mr. Trash Wheel", range = "A2:N655") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
mutate(
  sports_balls=as.integer(round(sports_balls)),
  identity = "mr",
  year=as.numeric(year)
)
knitr::kable(head(mr_trash_df,10))
```

| dumpster | month | year | date | weight_tons | volume_cubic_yards | plastic_bottles | polystyrene | cigarette_butts | glass_bottles | plastic_bags | wrappers | sports_balls | homes_powered | identity |
|---:|:---|---:|:---|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|:---|
| 1 | May | 2014 | 2014-05-16 | 4.31 | 18 | 1450 | 1820 | 126000 | 72 | 584 | 1162 | 7 | 0 | mr |
| 2 | May | 2014 | 2014-05-16 | 2.74 | 13 | 1120 | 1030 | 91000 | 42 | 496 | 874 | 5 | 0 | mr |
| 3 | May | 2014 | 2014-05-16 | 3.45 | 15 | 2450 | 3100 | 105000 | 50 | 1080 | 2032 | 6 | 0 | mr |
| 4 | May | 2014 | 2014-05-17 | 3.10 | 15 | 2380 | 2730 | 100000 | 52 | 896 | 1971 | 6 | 0 | mr |
| 5 | May | 2014 | 2014-05-17 | 4.06 | 18 | 980 | 870 | 120000 | 72 | 368 | 753 | 7 | 0 | mr |
| 6 | May | 2014 | 2014-05-20 | 2.71 | 13 | 1430 | 2140 | 90000 | 46 | 672 | 1144 | 5 | 0 | mr |
| 7 | May | 2014 | 2014-05-21 | 1.91 | 8 | 910 | 1090 | 56000 | 32 | 416 | 692 | 3 | 0 | mr |
| 8 | May | 2014 | 2014-05-28 | 3.70 | 16 | 3580 | 4310 | 112000 | 58 | 1552 | 3015 | 6 | 0 | mr |
| 9 | June | 2014 | 2014-06-05 | 2.52 | 14 | 2400 | 2790 | 98000 | 49 | 984 | 1988 | 6 | 0 | mr |
| 10 | June | 2014 | 2014-06-11 | 3.76 | 18 | 1340 | 1730 | 130000 | 75 | 448 | 1066 | 7 | 0 | mr |

Step 2b: Cleaning up Professor Trash

``` r
prof_trash_df=
  read_excel("datasets/trash_wheel_data2.xlsx", sheet="Professor Trash Wheel", range="A2:M123") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    identity="prof",
    year=as.numeric(year)
  )
knitr::kable(head(prof_trash_df,10))
```

| dumpster | month | year | date | weight_tons | volume_cubic_yards | plastic_bottles | polystyrene | cigarette_butts | glass_bottles | plastic_bags | wrappers | homes_powered | identity |
|---:|:---|---:|:---|---:|---:|---:|---:|---:|---:|---:|---:|---:|:---|
| 1 | January | 2017 | 2017-01-02 | 1.79 | 15 | 1950 | 6080 | 19700 | 8 | 3100 | 15600 | 29.83333 | prof |
| 2 | January | 2017 | 2017-01-30 | 1.58 | 15 | 9540 | 11230 | 17600 | 14 | 5630 | 16700 | 26.33333 | prof |
| 3 | February | 2017 | 2017-02-26 | 2.32 | 18 | 8350 | 9210 | 12000 | 19 | 6430 | 12400 | 38.66667 | prof |
| 4 | February | 2017 | 2017-02-26 | 3.72 | 15 | 8590 | 1030 | 13000 | 21 | 5870 | 11030 | 62.00000 | prof |
| 5 | February | 2017 | 2017-02-28 | 1.45 | 15 | 7830 | 9950 | 16000 | 18 | 7450 | 15340 | 24.16667 | prof |
| 6 | March | 2017 | 2017-03-30 | 1.71 | 15 | 8210 | 10340 | 14000 | 23 | 9560 | 13470 | 28.50000 | prof |
| 7 | April | 2017 | 2017-04-01 | 1.82 | 15 | 9830 | 11020 | 17000 | 26 | 11500 | 18620 | 30.33333 | prof |
| 8 | April | 2017 | 2017-04-20 | 2.37 | 15 | 9240 | 8760 | 15000 | 14 | 9970 | 14670 | 39.50000 | prof |
| 9 | May | 2017 | 2017-05-10 | 2.64 | 15 | 9540 | 8810 | 17000 | 28 | 12340 | 16580 | 44.00000 | prof |
| 10 | May | 2017 | 2017-05-26 | 2.78 | 15 | 8230 | 7800 | 13000 | 22 | 13450 | 17220 | 46.33333 | prof |

Step 2c: Cleaning up Gwynnda data

``` r
gwyn_trash_df=
  read_excel("datasets/trash_wheel_data2.xlsx", sheet="Gwynns Falls Trash Wheel", range = "A2:L266") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    identity="gwynn",
    year=as.numeric(year)
  )
knitr::kable(head(gwyn_trash_df,10))
```

| dumpster | month | year | date | weight_tons | volume_cubic_yards | plastic_bottles | polystyrene | cigarette_butts | plastic_bags | wrappers | homes_powered | identity |
|---:|:---|---:|:---|---:|---:|---:|---:|---:|---:|---:|---:|:---|
| 1 | July | 2021 | 2021-07-03 | 0.93 | 15 | 1200 | 360 | 3400 | 1800 | NA | 15.50000 | gwynn |
| 2 | July | 2021 | 2021-07-07 | 2.26 | 15 | 2000 | 240 | 3900 | 2200 | NA | 37.66667 | gwynn |
| 3 | July | 2021 | 2021-07-07 | 1.62 | 15 | 1800 | 270 | 2900 | 2400 | NA | 27.00000 | gwynn |
| 4 | July | 2021 | 2021-07-16 | 1.76 | 15 | 1000 | 180 | 2100 | 1800 | NA | 29.33333 | gwynn |
| 5 | July | 2021 | 2021-07-30 | 1.53 | 15 | 2100 | 240 | 4000 | 2700 | NA | 25.50000 | gwynn |
| 6 | August | 2021 | 2021-08-11 | 2.06 | 15 | 2400 | 360 | 3900 | 3000 | NA | 34.33333 | gwynn |
| 7 | August | 2021 | 2021-08-14 | 1.90 | 15 | 2700 | 320 | 4200 | 3200 | NA | 31.66667 | gwynn |
| 8 | August | 2021 | 2021-08-16 | 2.16 | 15 | 3000 | 320 | 4000 | 3600 | NA | 36.00000 | gwynn |
| 9 | August | 2021 | 2021-08-16 | 2.60 | 15 | 980 | 180 | 1800 | 1000 | NA | 43.33333 | gwynn |
| 10 | August | 2021 | 2021-08-17 | 3.21 | 15 | 240 | 42 | 400 | 360 | NA | 53.50000 | gwynn |

Step 2d: merging the data sets

``` r
trash_wheels = bind_rows(mr_trash_df,prof_trash_df,gwyn_trash_df)

knitr::kable(head(trash_wheels,15))
```

| dumpster | month | year | date | weight_tons | volume_cubic_yards | plastic_bottles | polystyrene | cigarette_butts | glass_bottles | plastic_bags | wrappers | sports_balls | homes_powered | identity |
|---:|:---|---:|:---|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|:---|
| 1 | May | 2014 | 2014-05-16 | 4.31 | 18 | 1450 | 1820 | 126000 | 72 | 584 | 1162 | 7 | 0 | mr |
| 2 | May | 2014 | 2014-05-16 | 2.74 | 13 | 1120 | 1030 | 91000 | 42 | 496 | 874 | 5 | 0 | mr |
| 3 | May | 2014 | 2014-05-16 | 3.45 | 15 | 2450 | 3100 | 105000 | 50 | 1080 | 2032 | 6 | 0 | mr |
| 4 | May | 2014 | 2014-05-17 | 3.10 | 15 | 2380 | 2730 | 100000 | 52 | 896 | 1971 | 6 | 0 | mr |
| 5 | May | 2014 | 2014-05-17 | 4.06 | 18 | 980 | 870 | 120000 | 72 | 368 | 753 | 7 | 0 | mr |
| 6 | May | 2014 | 2014-05-20 | 2.71 | 13 | 1430 | 2140 | 90000 | 46 | 672 | 1144 | 5 | 0 | mr |
| 7 | May | 2014 | 2014-05-21 | 1.91 | 8 | 910 | 1090 | 56000 | 32 | 416 | 692 | 3 | 0 | mr |
| 8 | May | 2014 | 2014-05-28 | 3.70 | 16 | 3580 | 4310 | 112000 | 58 | 1552 | 3015 | 6 | 0 | mr |
| 9 | June | 2014 | 2014-06-05 | 2.52 | 14 | 2400 | 2790 | 98000 | 49 | 984 | 1988 | 6 | 0 | mr |
| 10 | June | 2014 | 2014-06-11 | 3.76 | 18 | 1340 | 1730 | 130000 | 75 | 448 | 1066 | 7 | 0 | mr |
| 11 | June | 2014 | 2014-06-11 | 3.43 | 15 | 740 | 869 | 110000 | 38 | 344 | 544 | 6 | 0 | mr |
| 12 | June | 2014 | 2014-06-12 | 4.17 | 19 | 950 | 1140 | 133000 | 45 | 520 | 727 | 8 | 0 | mr |
| 13 | June | 2014 | 2014-06-13 | 5.13 | 15 | 530 | 630 | 104000 | 58 | 224 | 361 | 6 | 0 | mr |
| 14 | June | 2014 | 2014-06-13 | 4.17 | 15 | 840 | 760 | 100000 | 62 | 344 | 631 | 6 | 0 | mr |
| 15 | June | 2014 | 2014-06-19 | 3.28 | 15 | 1130 | 1350 | 102000 | 64 | 432 | 883 | 6 | 0 | mr |

``` r
total_weight_prof = prof_trash_df %>%
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))

total_cigs_gwyn = gwyn_trash_df %>%
  filter(year == 2022, month == "June") %>%
  summarise(total_cigs = sum(cigarette_butts, na.rm = TRUE))
```

The combined Trash Wheel dataset contains **1038** observations and
**15** variables. Some key variables included the weight of trash
collected, cigarette butts collected, plastic bottles, and identifier
for which trash wheel the data came from. Professor Trash Wheel
collected a total of **255.67** tons of trash. In June 2022, Gwyn
collected **1.812^{4}** cigarette butts.

## Problem 3

Step 3a:import and clean the data

``` r
zori_raw=
  read_csv("datasets/zillow_data/ZORI.csv",na=c("NA",".",""), show_col_types=FALSE) %>% 
  janitor::clean_names()

zip_raw=
  read_csv("datasets/zillow_data/ZIP.csv",na=c("NA",".",""),show_col_types = FALSE) %>% 
  janitor::clean_names()

zori_clean =
  zori_raw |>
  mutate(zip = as.character(region_name)) |>
  relocate(zip)

zip_clean =
  zip_raw |>
  mutate(zip = as.character(zip_code)) |>
  select(zip,
         borough = county,
         neighborhood)
```

Step 3B: need to make ZORI long format

``` r
zori_long=
  zori_clean %>% 
  pivot_longer(
    cols=x2015_01_31:x2024_08_31,
    names_to="date",
    values_to="rent") %>% 
 mutate(
   date=str_remove(date,"x")) %>% 
     select(zip,date,rent) %>% 
     arrange(zip,date)
```

Step 3C Part1: merging zip info due to warning error many

``` r
zip_one_per_zip =
  zip_clean |>
  group_by(zip) |>
  slice(1) |>     
  ungroup()
```

Some ZIP codes span multiple neighborhoods; to avoid row inflation later
on, I keep one neighborhood per ZIP (first alphabetically). This
preserves correct ZIP-level counts while keeping the dataset tidy.

Step 3C Part2: merge data sets

``` r
final_df=
  left_join(zori_long,zip_one_per_zip,by="zip") %>% 
  relocate(zip,borough,neighborhood,date,rent) %>% 
  arrange(zip,date)
```

Step 4: looking for unique zips and unique neighborhoods

``` r
unique_zips=length(unique(final_df$zip))
unique_neighborhoods=length(unique(na.omit(zip_clean$neighborhood)))
unique_zips
```

    ## [1] 149

``` r
unique_neighborhoods
```

    ## [1] 42

Since multiple neighborhoods were collapsed into a single string per ZIP
to keep the dataset tidy, counting neighborhoods directly from the final
dataset would understate the true number. To accurately report the
number of unique neighborhoods represented, I used the original ZIP code
file before collapsing. I still pulled zips from the final becasue those
stayed consistent. There **149 unique zips and 42 unique
neighbhorhoods.**

Step 5: now looking for zips that don’t show up in ZORI

``` r
zips_in_zori = tibble(zip = unique(zori_clean$zip))
zips_in_zip  = tibble(zip = unique(zip_clean$zip))

zips_not_in_zori_tbl =
  zip_clean |>
  anti_join(zips_in_zori, by = "zip") |>
  arrange(borough, zip)

zips_not_in_zori_amount=nrow(zips_not_in_zori_tbl)
zips_not_in_zori_amount
```

    ## [1] 171

``` r
knitr::kable(head(zips_not_in_zori_tbl, 15))
```

| zip   | borough | neighborhood               |
|:------|:--------|:---------------------------|
| 10464 | Bronx   | Southeast Bronx            |
| 10474 | Bronx   | Hunts Point and Mott Haven |
| 10475 | Bronx   | Northeast Bronx            |
| 10499 | Bronx   | NA                         |
| 10550 | Bronx   | NA                         |
| 10704 | Bronx   | NA                         |
| 10705 | Bronx   | NA                         |
| 10803 | Bronx   | NA                         |
| 11202 | Kings   | NA                         |
| 11224 | Kings   | Southern Brooklyn          |
| 11239 | Kings   | Canarsie and Flatlands     |
| 11241 | Kings   | NA                         |
| 11242 | Kings   | NA                         |
| 11243 | Kings   | NA                         |
| 11245 | Kings   | NA                         |

I found that there were **171** ZIP codes that appear in the NYC ZIP
file but are missing from Zori. For example, ZIP 10464 (Southeast
Bronx), ZIP 10474 (Hunts Point and Mott Haven), and ZIP 11224 (Southern
Brooklyn) are listed in the city ZIP file but not included in Zillow.
This likely reflects areas with limited rental housing,
industrial/commercial zones, or ZIP codes that are primarily PO
Box–only. Zillow excludes these areas because there would not be enough
info to calculate the Zori index.

Step 6: Compare rental prices in January 2021 to prices in January 2020.
Make a table that shows the 10 ZIP codes (along with the borough and
neighborhood) with largest drop in price from January 2020 to 2021.

``` r
jan_drop_tbl =
  final_df |>
  filter(date %in% c("2020_01_31", "2021_01_31")) |>
  group_by(zip, borough, neighborhood) |>
  summarise(
    jan2020 = rent[date == "2020_01_31"],
    jan2021 = rent[date == "2021_01_31"],
    .groups = "drop"
  ) |>
  mutate(drop_2020_to_2021 = jan2021 - jan2020) |>
  filter(!is.na(drop_2020_to_2021)) |>
  arrange(drop_2020_to_2021)
knitr::kable(head(jan_drop_tbl, 10))
```

| zip | borough | neighborhood | jan2020 | jan2021 | drop_2020_to_2021 |
|:---|:---|:---|---:|---:|---:|
| 10007 | New York | Lower Manhattan | 6334.211 | 5421.614 | -912.5966 |
| 10069 | New York | NA | 4623.042 | 3874.918 | -748.1245 |
| 10009 | New York | Lower East Side | 3406.442 | 2692.187 | -714.2550 |
| 10016 | New York | Gramercy Park and Murray Hill | 3731.135 | 3019.431 | -711.7045 |
| 10001 | New York | Chelsea and Clinton | 4108.098 | 3397.648 | -710.4499 |
| 10002 | New York | Lower East Side | 3645.416 | 2935.113 | -710.3028 |
| 10004 | New York | Lower Manhattan | 3149.658 | 2443.697 | -705.9608 |
| 10038 | New York | Lower Manhattan | 3573.201 | 2875.616 | -697.5853 |
| 10012 | New York | Greenwich Village and Soho | 3628.566 | 2942.344 | -686.2218 |
| 10010 | New York | Gramercy Park and Murray Hill | 3697.284 | 3012.353 | -684.9304 |
